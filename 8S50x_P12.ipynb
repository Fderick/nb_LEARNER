{"cells": [{"cell_type": "markdown", "id": "02dd2f9a", "metadata": {"id": "02dd2f9a", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Guided Problem Set 12: Higgs Search Part III </h1>\n"]}, {"cell_type": "markdown", "id": "7d8b809e", "metadata": {"id": "7d8b809e", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_12_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P12.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "fc477952", "metadata": {"id": "fc477952", "tags": ["learner", "md", "learner_chopped"]}, "source": ["<h3>Navigation</h3>\n", "\n", "<table style=\"width:100%\">\n", "     <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_12_1\">P12.1 Machine Learning for the Higgs Boson Search Part I</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problem_12_1\">P12.1 Problems</a></td>\n", "    </tr>   \n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_12_2\">P12.2 Machine Learning for the Higgs Boson Search Part II</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problem_12_2\">P12.2 Problems</a></td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_12_3\">P12.3 Machine Learning for the Higgs Boson Search Part III</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problem_12_3\">P12.3 Problems</a></td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "178cf1d4", "metadata": {"id": "178cf1d4", "tags": ["learner", "md", "catsoop_00"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "In this Pset, we apply Machine Learning to the Higgs Boson search. We continue with the same data set used in previous Psets."]}, {"cell_type": "markdown", "id": "ebe83f47", "metadata": {"id": "178cf1d4", "tags": ["learner", "md", "catsoop_00", "learner_chopped"]}, "source": ["<h3>Data</h3>\n", "\n", ">description: Higgs to 4 Leptons with CMS Open data from the Large Hadron Collider<br>\n", ">source: https://zenodo.org/record/8034556 <br>\n", ">attribution: Philip Harris (CMS Collaboration), DOI:10.5281/zenodo.8034556 \n"]}, {"cell_type": "code", "execution_count": null, "id": "e9261811", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "1kNzU4xDavLK", "outputId": "2b8854b8-3121-4631-8cd2-5f2a21d988e1", "tags": ["learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell00\n", "\n", "!git init\n", "!git remote add -f origin https://github.com/mitx-8s50/nb_LEARNER/\n", "!git config core.sparseCheckout true\n", "!echo 'P09' >> .git/info/sparse-checkout\n", "!git pull origin main"]}, {"cell_type": "code", "execution_count": null, "id": "e61ff020", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "1kNzU4xDavLK", "outputId": "2b8854b8-3121-4631-8cd2-5f2a21d988e1", "tags": ["learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell01\n", "\n", "# NOTE: some files are too large to include in the original repository, so you must download them from here:\n", "# https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AAAXOXeEO9Bl_W6BUhV61kFpa?dl=0\n", "#\n", "# Ways to download:\n", "#     1. Copy/paste the link (replace =0 with =1 to download automatically)\n", "#     2. Use the wget commands below (works in Colab, but you may need to install wget if using locally)\n", "#\n", "# Location of files:\n", "#     Move the files to the directory data/P09/MC\n", "#\n", "# Using wget: (works in Colab)\n", "#     Upon downloading, the code below will move them to the appropriate directory\n", "\n", "!wget https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AADnJ6f0zzYekvFunRpH13Gma/zzto2mu2e2011.csv?dl=0\n", "!wget https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AAAgZQdH4nWP9dYUmDLWXfhXa/zzto2mu2e2012.csv?dl=0\n", "!wget https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AADepq5NkiLgh0uaij8P9p1Ka/zzto4e2011.csv?dl=0\n", "!wget https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AAA4FHGuNlPcfXHgwCcqZAyva/zzto4e2012.csv?dl=0\n", "!wget https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AAAxiJAH_89oEYYvfMpFdtq4a/zzto4mu2011.csv?dl=0\n", "!wget https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AAD6lR-feTLWa1-GvYCsy8N5a/zzto4mu2012.csv?dl=0\n", "!mv zzto2mu2e2011.csv?dl=0 data/P09/MC/zzto2mu2e2011.csv\n", "!mv zzto2mu2e2012.csv?dl=0 data/P09/MC/zzto2mu2e2012.csv\n", "!mv zzto4e2011.csv?dl=0 data/P09/MC/zzto4e2011.csv\n", "!mv zzto4e2012.csv?dl=0 data/P09/MC/zzto4e2012.csv\n", "!mv zzto4mu2011.csv?dl=0 data/P09/MC/zzto4mu2011.csv\n", "!mv zzto4mu2012.csv?dl=0 data/P09/MC/zzto4mu2012.csv"]}, {"cell_type": "markdown", "id": "5cf300ff", "metadata": {"id": "5cf300ff", "tags": ["learner", "md"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook."]}, {"cell_type": "code", "execution_count": null, "id": "1kNzU4xDavLK", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "1kNzU4xDavLK", "outputId": "2b8854b8-3121-4631-8cd2-5f2a21d988e1", "tags": ["learner", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell02\n", "\n", "!pip install lmfit\n", "!pip install dcor\n", "!pip install torch\n", "!pip install sklearn"]}, {"cell_type": "code", "execution_count": null, "id": "06bdc10f", "metadata": {"id": "06bdc10f", "tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell03\n", "\n", "import numpy as np               #https://numpy.org/doc/stable/\n", "import matplotlib.pyplot as plt  #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n", "import pandas as pd              #https://pandas.pydata.org/docs/user_guide/index.html\n", "from scipy import stats\n", "import scipy.optimize as optimize\n", "import lmfit\n", "\n", "import torch\n", "import torch.nn as nn\n", "from torch.utils.data import Dataset\n", "from torch.autograd import Variable\n", "from sklearn.model_selection import train_test_split"]}, {"cell_type": "markdown", "id": "2305bb60", "metadata": {"id": "2305bb60", "tags": ["learner", "md"]}, "source": ["<h3>Setting Default Figure Parameters</h3>\n", "\n", "The following code cell sets default values for figure parameters."]}, {"cell_type": "code", "execution_count": null, "id": "f957ae03", "metadata": {"id": "f957ae03", "tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell04\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure parameters\n", "plt.rcParams['figure.figsize'] = (9,6)\n", "\n", "medium_size = 12\n", "large_size = 15\n", "\n", "plt.rc('font', size=medium_size)          # default text sizes\n", "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n", "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n", "plt.rc('legend', fontsize=medium_size)    # legend\n", "plt.rc('axes', titlesize=large_size)      # axes title\n", "plt.rc('axes', labelsize=large_size)      # x and y labels\n", "plt.rc('figure', titlesize=large_size)    # figure title\n"]}, {"cell_type": "markdown", "id": "8d145afd", "metadata": {"id": "2305bb60", "tags": ["learner", "md"]}, "source": ["<h3>Loading Data and Defining Relevant Functions Used Previously</h3>\n", "\n", "Run all cells below before continuing. You will have to complete some cells based on your work in previous Psets. These cells will be indicated below."]}, {"cell_type": "code", "execution_count": null, "id": "e200568d", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell05\n", "\n", "## some scale factors and constants relevant to the data\n", "\n", "## mass squared of muon: m_muon^2 (in GeV)\n", "sqm1 = (0.105658) * (0.105658)\n", "## mass squared of electron: m_e^2 (in GeV)\n", "sqme = (0.0005109989) * (0.0005109989)\n", "## mass of Z boson (in GeV)\n", "mZ = 91.1876\n", "\n", "\n", "## constants for the scale factor of MC. The MC is produced at a certain cross section\n", "## with a certain number of events. To increase statistics, the event numbers generated are usually very large,\n", "## therefore a scale factor is needed to apply on the MC to make them agree with data.\n", "## Scale factor for each MC component is: lumi * xsec / nevt, as provided below\n", "\n", "## Luminosity of each year in pb\n", "lumi12 = 11580.\n", "lumi11 = 2330.\n", "\n", "## MC cross section of each process\n", "xsecZZ412 = 0.107\n", "xsecZZ2mu2e12 = 0.249\n", "xsecZZ411 = 0.093\n", "xsecZZ2mu2e11 = 0.208\n", "\n", "xsecTTBar12 = 200.\n", "xsecTTBar11 = 19.504\n", "\n", "xsecDY5012 = 2955.\n", "xsecDY1012 = 10.742\n", "xsecDY5011 = 2475.\n", "xsecDY1011 = 9507.\n", "  \n", "scalexsecHZZ12 = 0.0065\n", "scalexsecHZZ11 = 0.0057\n", "\n", "## Number of MC Events generated for each process\n", "nevtZZ4mu12 = 1499064\n", "nevtZZ4e12 = 1499093\n", "nevtZZ2mu2e12 = 1497445\n", "nevtHZZ12 = 299973 \n", "nevtTTBar12 = 6423106\n", "nevtDY5012 = 29426492\n", "nevtDY1012 = 6462290\n", "  \n", "nevtZZ4mu11 = 1447136\n", "nevtZZ4e11 = 1493308\n", "nevtZZ2mu2e11 = 1479879\n", "nevtHZZ11 = 299683\n", "nevtTTBar11 = 9771205\n", "nevtDY5011 = 36408225\n", "nevtDY1011 = 39909640\n", "\n", "\n", "labels = ['$m_{H}$ = 125 GeV', r'ZZ $\\rightarrow$ 4l', 'Z/$\\gamma^{*}$ + X', r'$t\\bar{t}$']\n", "colors = ['r','b','g','gray']\n", "\n", "#now we compute the event weights\n", "scales_higgs = [lumi11*scalexsecHZZ11/nevtHZZ11, lumi12*scalexsecHZZ12/nevtHZZ12]\n", "scales_zz = [lumi11*xsecZZ411/nevtZZ4mu11, lumi11*xsecZZ2mu2e11/nevtZZ2mu2e11, lumi11*xsecZZ411/nevtZZ4e11,\\\n", "             lumi12*xsecZZ412/nevtZZ4mu12, lumi12*xsecZZ2mu2e12/nevtZZ2mu2e12, lumi12*xsecZZ412/nevtZZ4e12]\n", "scales_dy = [lumi11*xsecDY1011/nevtDY1011, lumi11*xsecDY5011/nevtDY5011, \\\n", "             lumi12*xsecDY1012/nevtDY1012, lumi11*xsecDY5012/nevtDY5012]\n", "scales_tt = [lumi11*xsecTTBar11/nevtTTBar11, lumi12*xsecTTBar12/nevtTTBar12]"]}, {"cell_type": "code", "execution_count": null, "id": "2991ae5c", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell06\n", "\n", "### open the files ###\n", "# read datalist of each year and combine to one \n", "\n", "def loaddata():\n", "    data_year  = [pd.read_csv('data/P09/clean_data_2011.csv',index_col=None, header=0)]\n", "    data_year += [pd.read_csv('data/P09/clean_data_2012.csv',index_col=None, header=0)]\n", "    pdata = pd.concat(data_year,axis=0,ignore_index=True)\n", "    return pdata\n", "\n", "data=loaddata()"]}, {"cell_type": "code", "execution_count": null, "id": "9a8a0ba9", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell07\n", "\n", "## ZZ*\n", "#NOTE: these zz* files are too large to include the original repository, so you must download them here:\n", "#https://www.dropbox.com/sh/wf7d42jg4mfbdlh/AAAXOXeEO9Bl_W6BUhV61kFpa?dl=0\n", "#Run cell P10.6-runcell01 to do this\n", "\n", "def loadMC():\n", "    # read MClist of each process and each year\n", "    mc_higgs_11 = pd.read_csv('data/P09/MC/higgs2011.csv',index_col=None, header=0)\n", "    mc_higgs_12 = pd.read_csv('data/P09/MC/higgs2012.csv',index_col=None, header=0)\n", "    ## Drell-Yan\n", "    mc_dy10_11 = pd.read_csv('data/P09/MC/dy1050_2011.csv',index_col=None, header=0)\n", "    mc_dy50_11 = pd.read_csv('data/P09/MC/dy50_2011.csv',index_col=None, header=0)\n", "    mc_dy10_12 = pd.read_csv('data/P09/MC/dy1050_2012.csv',index_col=None, header=0)\n", "    mc_dy50_12 = pd.read_csv('data/P09/MC/dy50_2012.csv',index_col=None, header=0)\n", "    ## ttbar\n", "    mc_ttbar_11 = pd.read_csv('data/P09/MC/ttbar2011.csv',index_col=None, header=0)\n", "    mc_ttbar_12 = pd.read_csv('data/P09/MC/ttbar2012.csv',index_col=None, header=0)\n", "    ##zz\n", "    mc_zz4mu_11 = pd.read_csv('data/P09/MC/zzto4mu2011.csv',index_col=None, header=0)\n", "    mc_zz2mu2e_11 = pd.read_csv('data/P09/MC/zzto2mu2e2011.csv',index_col=None, header=0)\n", "    mc_zz4e_11 = pd.read_csv('data/P09/MC/zzto4e2011.csv',index_col=None, header=0)\n", "    mc_zz4mu_12 = pd.read_csv('data/P09/MC/zzto4mu2012.csv',index_col=None, header=0)\n", "    mc_zz2mu2e_12 = pd.read_csv('data/P09/MC/zzto2mu2e2012.csv',index_col=None, header=0)\n", "    mc_zz4e_12 = pd.read_csv('data/P09/MC/zzto4e2012.csv',index_col=None, header=0)\n", "\n", "    # create a combined list of MC\n", "    mc_higgs = [mc_higgs_11, mc_higgs_12]\n", "    mc_zz = [mc_zz4mu_11, mc_zz2mu2e_11, mc_zz4e_11, mc_zz4mu_12, mc_zz2mu2e_12, mc_zz4e_12]\n", "    mc_dy = [mc_dy10_11, mc_dy50_11, mc_dy10_12, mc_dy50_12]\n", "    mc_tt = [mc_ttbar_11, mc_ttbar_12]\n", "\n", "    out_mc_sig = pd.concat(mc_higgs,axis=0,ignore_index=True)\n", "    out_mc_bkg_zz = pd.concat(mc_zz,axis=0,ignore_index=True)\n", "    out_mc_bkg_dy = pd.concat(mc_dy,axis=0,ignore_index=True)\n", "    out_mc_bkg_tt = pd.concat(mc_tt,axis=0,ignore_index=True)\n", "\n", "    ## For Selections:\n", "    out_mc_all = [mc_higgs, mc_zz, mc_dy, mc_tt]\n", "    return out_mc_all,out_mc_sig,out_mc_bkg_zz,out_mc_bkg_dy,out_mc_bkg_tt\n", "\n", "mc_all,mc_sig,mc_bkg_zz,mc_bkg_dy,mc_bkg_tt=loadMC()"]}, {"cell_type": "code", "execution_count": null, "id": "b078d4e4", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell08\n", "\n", "#This is the header of the csv file:\n", "#Run,Event,PID1,Q1,E1,px1,py1,pz1,eta1,phi1,PID2,Q2,E2,px2,py2,pz2,eta2,phi2,PID3,Q3,E3,px3,py3,pz3,eta3,phi3,PID4,Q4,E4,px4,py4,pz4,eta4,phi4\n", "def ReadEntries(lis):\n", "    return lis['PID1'],lis['Q1'],lis['E1'],lis['px1'],lis['py1'],lis['pz1'],lis['eta1'],lis['phi1'], \\\n", "    lis['PID2'],lis['Q2'],lis['E2'],lis['px2'],lis['py2'],lis['pz2'],lis['eta2'],lis['phi2'], \\\n", "    lis['PID3'],lis['Q3'],lis['E3'],lis['px3'],lis['py3'],lis['pz3'],lis['eta3'],lis['phi3'], \\\n", "    lis['PID4'],lis['Q4'],lis['E4'],lis['px4'],lis['py4'],lis['pz4'],lis['eta4'],lis['phi4']\n", "\n", "def pt(px, py):\n", "    return np.sqrt(px**2 + py**2)\n", "\n", "def invMass(E, px, py, pz):\n", "    return np.sqrt(E**2 - (px**2 + py**2 + pz**2))\n", "\n", "def InvMass_4l(lists):   ### faster way to get the 4l-system invMass directly from the list, as you may repeately run it for the final plot###\n", "    E_tot = lists['E1'] + lists['E2'] + lists['E3'] + lists['E4']\n", "    px_tot = lists['px1'] + lists['px2'] + lists['px3'] + lists['px4']\n", "    py_tot = lists['py1'] + lists['py2'] + lists['py3'] + lists['py4']\n", "    pz_tot = lists['pz1'] + lists['pz2'] + lists['pz3'] + lists['pz4']\n", "    return np.sqrt(E_tot**2 - (px_tot**2 + py_tot**2 + pz_tot**2))"]}, {"cell_type": "markdown", "id": "2f1217d1", "metadata": {"id": "2305bb60", "tags": ["learner", "md"]}, "source": ["<h3>Complete Cell Below Based on Previous Work</h3>\n"]}, {"cell_type": "code", "execution_count": null, "id": "1c54bc5d", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell09\n", "\n", "def select_pairs(PID1,PID2,PID3,m_z1_c1,m_z2_c1,m_z1_c2,m_z2_c2,m_z1_c3,m_z2_c3,upperMinMass,lowerMinMass):\n", "    ### 2mu2e event, only one combination c3\n", "        \n", "    ### 2mu2e event, only one combination c2\n", "\n", "    ### 4mu or 4e event, 3 different combination\n", "\n", "    return pass"]}, {"cell_type": "code", "execution_count": null, "id": "0e551cda", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell10\n", "\n", "def obj(pid,px,py,eta):  ## object selection for a single object\n", "    pt_obj = pt(px,py)\n", "    if (np.abs(pid) == 13 and pt_obj > 5.) or (np.abs(pid) == 11 and pt_obj > 7.):## requires electrons and muons to have transverse momenta above certain level\n", "        return 1\n", "    else:\n", "        return 0\n", "    \n", "def objsel(lis):  ## Create column indicating whether this event passes the object selection\n", "    pass_obj = []\n", "    for row in lis.itertuples():   ## loop over each event(each row)\n", "        pass_obj.append(obj(row.PID1,row.px1,row.py1,row.eta1) and obj(row.PID2,row.px2,row.py2,row.eta2) and obj(row.PID3,row.px3,row.py3,row.eta3) and obj(row.PID4,row.px4,row.py4,row.eta4))\n", "    lis['PassObj'] = pass_obj  "]}, {"cell_type": "markdown", "id": "b0a086e8", "metadata": {"id": "2305bb60", "tags": ["learner", "md"]}, "source": ["<h3>Complete Cell Below Based on Previous Work</h3>\n"]}, {"cell_type": "code", "execution_count": null, "id": "a5a412bd", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell11\n", "\n", "def evt(PID1,Q1,E1,px1,py1,pz1,PID2,Q2,E2,px2,py2,pz2,PID3,Q3,E3,px3,py3,pz3,PID4,Q4,E4,px4,py4,pz4):\n", "    \n", "    if PID1+PID2+PID3+PID4 != 0: #Charge conservation\n", "        return 0\n", "    \n", "    ### All Pairwise Mass combinations\n", "    ##c1\n", "    m_z1_c1 = np.sqrt((E1+E2)**2 - ((px1+px2)**2 + (py1+py2)**2 + (pz1+pz2)**2))\n", "    m_z2_c1 = np.sqrt((E3+E4)**2 - ((px3+px4)**2 + (py3+py4)**2 + (pz3+pz4)**2))\n", "    ##c2\n", "    m_z1_c2 = np.sqrt((E1+E3)**2 - ((px1+px3)**2 + (py1+py3)**2 + (pz1+pz3)**2))\n", "    m_z2_c2 = np.sqrt((E2+E4)**2 - ((px2+px4)**2 + (py2+py4)**2 + (pz2+pz4)**2))\n", "    ##c3\n", "    m_z1_c3 = np.sqrt((E1+E4)**2 - ((px1+px4)**2 + (py1+py4)**2 + (pz1+pz4)**2))\n", "    m_z2_c3 = np.sqrt((E2+E3)**2 - ((px2+px3)**2 + (py2+py3)**2 + (pz2+pz3)**2))\n", "\n", "    ###NOTE: IF YOU DID NOT PREVIOUSLY DEFINE THE `lowerMinMass` and `upperMinMass`, do so here\n", "    lowerMinMass = 0 #YOUR VALUE HERE\n", "    upperMinMass = 0 #YOUR VALUE HERE\n", "\n", "    if select_pairs(PID1,PID2,PID3,m_z1_c1,m_z2_c1,m_z1_c2,m_z2_c2,m_z1_c3,m_z2_c3,upperMinMass,lowerMinMass) == 0:\n", "      return 0\n", "        \n", "    return 1    \n", "    \n", "    \n", "def evtsel(lis):   ### Similar as the Function: objsel shown above\n", "    pass_evt = []\n", "    for row in lis.itertuples():\n", "        pass_evt.append(evt(row.PID1,row.Q1,row.E1,row.px1,row.py1,row.pz1,\\\n", "                            row.PID2,row.Q2,row.E2,row.px2,row.py2,row.pz2,\\\n", "                            row.PID3,row.Q3,row.E3,row.px3,row.py3,row.pz3,\\\n", "                            row.PID4,row.Q4,row.E4,row.px4,row.py4,row.pz4))\n", "    lis['PassEvt'] = pass_evt"]}, {"cell_type": "code", "execution_count": null, "id": "808a0127", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell12\n", "\n", "def HistInvMass4l(lis, scales, rmin, rmax, nbins):\n", "    hist_lis = []\n", "    for i,pro in enumerate(lis):\n", "        invM = InvMass_4l(pro)\n", "        hist, bins = np.histogram(invM, bins = nbins, range = (rmin,rmax))\n", "        hist = hist * scales[i]\n", "        hist_lis.append(hist)\n", "    return sum(hist_lis)\n", "\n", "def makeAllHists(idata,imc,rmin=50,rmax=200,nbins=50):\n", "    hist_higgs = HistInvMass4l(imc[0],scales_higgs,rmin, rmax, nbins)\n", "    hist_zz    = HistInvMass4l(imc[1],scales_zz,rmin, rmax, nbins)\n", "    hist_dy    = HistInvMass4l(imc[2],scales_dy,rmin, rmax, nbins)\n", "    hist_tt    = HistInvMass4l(imc[3],scales_tt,rmin, rmax, nbins)\n", "    out_hist_mc    = [hist_tt, hist_dy, hist_zz, hist_higgs]\n", "\n", "    inM_data = InvMass_4l(idata)\n", "    out_hist_data, bins = np.histogram(inM_data, bins = nbins, range = (rmin,rmax))\n", "    return out_hist_mc,out_hist_data"]}, {"cell_type": "code", "execution_count": null, "id": "08fd4b0b", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell13\n", "\n", "def plotHists(ihist_mc,ihist_data,rmin=50,rmax=200,nbins=50):\n", "    plt.figure(figsize = (8,6))\n", "    # plt.style.use('mystyle.mplstyle')\n", "    binwidth  = (rmax-rmin)//nbins\n", "    bincenter = np.arange(rmin+binwidth*0.5,rmax+binwidth*0.5,binwidth)\n", "    ## MC\n", "    for i,pro in enumerate(ihist_mc):\n", "        if i == 0:\n", "            stack = plt.bar(bincenter, pro, align = 'center', width = binwidth, color = colors[3-i], label=labels[3-i],\n", "            alpha = 0.5)\n", "            bot = pro\n", "        else:\n", "            stack = plt.bar(bincenter, pro, align = 'center', width = binwidth, color = colors[3-i], label=labels[3-i],\n", "                 bottom = bot, alpha = 0.5)\n", "            bot = bot + pro\n", "\n", "    ## Measured data\n", "    xerrs = [binwidth*0.5 for i in range(0, nbins)]\n", "    yerrs = np.sqrt(ihist_data)\n", "    marker_data = plt.errorbar(bincenter, ihist_data, xerr = xerrs, yerr = yerrs, linestyle = 'None', color = 'black',\n", "                        marker = 'o', label = 'Data')\n", "\n", "    plt.title('$ \\sqrt{s} = 7$ TeV, L = 2.3 $fb^{-1}$; $\\sqrt{s} = 8$ TeV, L = 11.6 $fb^{-1}$ \\n', fontsize = 15, position=(0.64,0.95))\n", "    plt.xlabel('$m_{4l}$ [GeV]',fontsize = 20, position=(0.92,0.1))\n", "    plt.ylabel('Events / 3 GeV',fontsize = 20, position=(0.1,0.84))\n", "    plt.xlim(rmin,rmax)\n", "    plt.legend(fontsize = 20)\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "3c8476ba", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell14\n", "\n", "#load the interpolation package\n", "from scipy import interpolate\n", "\n", "def setupSpline(ihist_mc,rmin=50,rmax=200,nbins=50):\n", "    binwidth    = (rmax-rmin)//nbins\n", "    bincenter   =  np.arange(rmin+binwidth*0.5,rmax+binwidth*0.5,binwidth)\n", "    sig=hist_mc[-1]\n", "    ## Sum over all the backgrounds and plot at the same time\n", "    sumbkg=0\n", "    for i,pro in enumerate(ihist_mc):\n", "        if i == 0:\n", "            stack = plt.bar(bincenter, pro, align = 'center', width = binwidth, color = colors[3-i], label=labels[3-i],alpha = 0.5)\n", "            bot = pro\n", "        else:\n", "            stack = plt.bar(bincenter, pro, align = 'center', width = binwidth, color = colors[3-i], label=labels[3-i],bottom = bot, alpha = 0.5)\n", "            bot = bot + pro\n", "        if i == 2:\n", "            sumbkg = bot\n", "    plt.bar(bincenter,sumbkg,align='center',width=binwidth)\n", "\n", "    #spline interpolate\n", "    out_bkg_interpolate = interpolate.splrep(bincenter, sumbkg)\n", "    out_sig_interpolate = interpolate.splrep(bincenter, sig)\n", "\n", "    #Now plot the splines as a function evaluation\n", "    x_int = np.linspace(50, 200,1000)\n", "    #this is the evalution\n", "    y_bkg = interpolate.splev(x_int, out_bkg_interpolate)\n", "    y_sig = interpolate.splev(x_int, out_sig_interpolate)\n", "    plt.plot(x_int, y_bkg, 'b',label='bkg')\n", "    plt.plot(x_int, y_sig+y_bkg, 'r',label='sig+bkg')\n", "    #plt.plot(x,y_mc,drawstyle = 'steps-mid')\n", "    plt.xlabel(\"$m_{4\\ell}$(GeV)\")\n", "    plt.ylabel(\"$N_{events}$\")\n", "    plt.legend()\n", "    plt.show()\n", "    return out_sig_interpolate,out_bkg_interpolate\n"]}, {"cell_type": "markdown", "id": "2849db0a", "metadata": {"id": "2305bb60", "tags": ["learner", "md"]}, "source": ["<h3>Complete Cell Below Based on Previous Work</h3>\n"]}, {"cell_type": "code", "execution_count": null, "id": "d3755704", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell15\n", "\n", "#ok lets setup the fit now that we have the ability to interpolate \n", "#as a first pass we will just fit the data with lmfit\n", "import lmfit \n", "\n", "def conGaus(x,tck,sigma=1,mean=0,iMin=-3,iMax=3,iN=10):\n", "    step=float((iMax-iMin))/float(iN)\n", "    pInt=0\n", "    for i0 in range(iN):\n", "            pX   = (i0*step+iMin)*sigma\n", "            pVal = interpolate.splev(x-pX,tck)*(stats.norm.pdf(pX,mean,sigma))\n", "            pInt += pVal*step\n", "    return pInt\n", "\n", "def sigbkg(x,mh,shift,bkgnorm=1,signorm=1,sigma=1):\n", "    y_bkg = conGaus(x+shift, bkg_interpolate,sigma)\n", "    y_sig = conGaus(x+(mh-125), sig_interpolate,sigma)\n", "    return y_bkg*bkgnorm + y_sig*signorm\n", "\n", "def bkg(x,mh,shift,bkgnorm=1,sigma=1):\n", "    y_bkg = conGaus(x+shift, bkg_interpolate,sigma)\n", "    return y_bkg*bkgnorm\n", "\n", "def fitModel(iM,iX,iY,iWeights,iFunc):\n", "    model  = lmfit.Model(iFunc)\n", "    p = model.make_params(mh=iM,shift=0,bkgnorm=1,signnorm=1)\n", "    p['mh'].vary=False\n", "    result = model.fit(data=iY,params=p,x=iX,weights=iWeights)\n", "    xinterp = np.arange(iX[0],iX[-1],0.1)\n", "    output = model.eval(params=result.params,x=xinterp)\n", "    return xinterp,output,result\n", "\n", "def fithistograms(iM,idata_hist,ifunc,rmin=50,rmax=200,nbins=50,plot=False):\n", "    binwidth    = (rmax-rmin)//nbins\n", "    bincenter   =  np.arange(rmin+binwidth*0.5,rmax+binwidth*0.5,binwidth)\n", "    nonzerobin = bincenter[idata_hist > 0]\n", "    nonzerohist= idata_hist[idata_hist > 0]\n", "    error      = np.sqrt(idata_hist[idata_hist > 0])\n", "    xinterp,output,result2 = fitModel(iM,nonzerobin,nonzerohist,1./error,ifunc)\n", "    if plot:\n", "        plt.errorbar(nonzerobin,nonzerohist, yerr = error, linestyle = 'None', color = 'black', marker = 'o', label = 'Data')\n", "        plt.plot(xinterp,output)\n", "        lmfit.report_fit(result2)\n", "        plt.show()\n", "    return result2.chisqr\n", "\n", "    \n", "def shiftbkg(x,mh,shift,bkgnorm=1):\n", "    y_bkg = interpolate.splev(x+shift, bkg_interpolate)\n", "    return y_bkg*bkgnorm\n"]}, {"cell_type": "code", "execution_count": null, "id": "faa53798", "metadata": {"tags": ["learner", "py", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.0-runcell16\n", "\n", "\n", "def massscan(isigbkg,plot=True):\n", "    mhscan = np.arange(110,150,.1)\n", "    NLLs   = np.array([])\n", "    pscan  = np.array([])\n", "    sigscan  = np.array([])\n", "    for pMH in mhscan: \n", "        chi2sig = fithistograms(pMH,hist_data,isigbkg)\n", "        NLL,pval,sigma=get_significance_vals(chi2sig,chi2bkg,1)\n", "        NLLs  = np.append(NLLs,-2*NLL)\n", "        pscan = np.append(pscan,pval)\n", "        sigscan = np.append(sigscan,sigma)\n", "    \n", "    NLLs = NLLs-np.min(NLLs)\n", "    if plot:\n", "        plt.plot(mhscan,NLLs)\n", "        plt.xlabel(\"m$_{h}$ (125)\")\n", "        plt.ylabel(\"2 log($\\Lambda_{1}/\\Lambda_{2}$)\")\n", "        plt.show()\n", "\n", "        plt.plot(mhscan,pscan)\n", "        plt.xlabel(\"m$_{h}$ (125)\")\n", "        plt.ylabel(\"p\")\n", "        plt.show()\n", "    \n", "        plt.plot(mhscan,sigscan)\n", "        plt.xlabel(\"m$_{h}$ (125)\")\n", "        plt.ylabel(\"$\\sigma$\")\n", "        plt.show()\n", " \n", "    return mhscan,NLLs,pscan\n", "\n", "def get_significance_vals(iChiSB,iChiB,iNDF=2):\n", "    NLL   = 0.5*(iChiB-iChiSB)\n", "    pval  = 1-stats.chi2.cdf(2*NLL,iNDF)\n", "    sigma = -1.*stats.norm.ppf(pval/2)\n", "    return NLL,pval,sigma\n", "\n", "\n", "def mass(imscan, iNLLs,iMin=110,iMax=135):\n", "    NLLinterp=interpolate.splrep(imscan,iNLLs-1)\n", "    bestm = mhscan[np.argmin(iNLLs)]\n", "    def NLLfunc(iX): \n", "        return interpolate.splev(iX,NLLinterp)\n", "    sol0 = optimize.root_scalar(NLLfunc, bracket=[iMin, bestm], method='brentq')\n", "    sol1 = optimize.root_scalar(NLLfunc, bracket=[bestm, iMax], method='brentq')\n", "    print(\"Mass window is:\", [sol0.root,sol1.root],\"Best fit:\",bestm,\"+/-\",(sol1.root-sol0.root)/2.)\n"]}, {"cell_type": "markdown", "id": "964aa670", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_12_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P12.1 Machine Learning for the Higgs Boson Search Part I</h2>   \n", "\n", "| [Top](#section_12_0) | [Previous Section](#section_12_0) | [Problems](#problem_12_1) | [Next Section](#section_12_2) |"]}, {"cell_type": "markdown", "id": "c3a8f74a", "metadata": {"tags": ["learner", "md", "catsoop_01"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now that we found the Higgs boson and we measured properties about the Higgs boson, we want to understand how we can use deep learning to improve our Higgs boson search. For this part of the lecture, we will train a neural network to reject the background, and then we will try to measure the Higgs boson again. \n", "\n", "While this might seem daunting, this is actually pretty similar to what was done at the time of the Higgs boson discovery, the tools and experience here will give an idea of both the challenges and wins of deep learning for the Higgs boson discovery. \n", "\n", "For this, what we are going to do is use our existing MC samples to train a deep learning algorithm to discriminate the Higgs boson from the background. \n", "\n", "First lets make sure we have all the tools we need to do this. We are going to use pytorch for this. "]}, {"cell_type": "markdown", "id": "8422a43f", "metadata": {"id": "2DeiEP9aH6eD", "tags": ["learner", "md", "catsoop_01"]}, "source": ["<h3>Making the Datasets</h3>\n", "\n", "Now that we have that all, we can go ahead and make datasets. To start with, we are going to just take one variable and train a neural network. This variable is just going to be $E_{1}$ (aka E1) the energy of the first lepton in our dataset. Let's go ahead and do that. \n", "\n", "For the neural network ware going to do a few steps. Let's list these steps out : \n", "\n", "1. Use our MC simulation to train the neural network\\\n", "2. Train a single output neural network to discriminate\\\n", "      a. We will use the Higgs as signal, label target 1\\\n", "      b. We will use the ZZ as background, label it target 0\n", "      \n", "3. Make sure the neural network is balanced by selecting an even number of signal and background events\\\n", "4. For this network we are going to apply our previous 4-lepton selection, and see if we can improve our significance on top of what we had before.\n", "\n", "One thing you will note is that we are going to split our dataset into a training and validation dataset so that we can check the neural network performance. "]}, {"cell_type": "code", "execution_count": null, "id": "Z8KddES2UR6h", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "id": "Z8KddES2UR6h", "outputId": "04ea375c-aa1a-4199-c143-f74b42e669ce", "tags": ["learner", "py", "learner_chopped", "catsoop_01"]}, "outputs": [], "source": ["#>>>RUN: P12.1-runcell01\n", "\n", "def setupMCAll(iquery='PassObj == 1 and PassEvt == 1'):\n", "    mc_all,mc_sig,mc_bkg_zz,mc_bkg_dy,mc_bkg_tt=loadMC()\n", "    for i,bkg in enumerate(mc_all):\n", "        for j,pro in enumerate(bkg):\n", "            objsel(pro)\n", "            evtsel(pro)\n", "            mc_all[i][j] = pro.query(iquery)\n", "    return mc_all\n", "\n", "def prepDataSets(iVar=['E1']):\n", "    mc_all=setupMCAll()\n", "    #Our signal is going to Higgs and ZZ\n", "    sig=np.append(mc_all[0][0][iVar].values,mc_all[0][1][iVar].values) #Higgs sample [0]\n", "    bkg=np.append(mc_all[1][0][iVar].values,mc_all[1][1][iVar].values) #ZZ sample [1]\n", "    #Now \n", "    minlen=np.minimum(len(sig),len(bkg))\n", "    bkg=bkg[0:minlen]\n", "    sig=sig[0:minlen]\n", "    total =np.append(bkg,sig)\n", "    print(total,len(total))\n", "    print(len(iVar),iVar)\n", "    total =np.reshape(total,(len(total)//len(iVar),len(iVar)))\n", "    labels=np.append(np.zeros(len(bkg)//len(iVar)),np.ones(len(sig)//len(iVar)))\n", "    tot_train, tot_valid, label_train, label_valid=train_test_split(total,labels,test_size=0.3, random_state=42,shuffle=True)\n", "    return tot_train, tot_valid, label_train, label_valid\n", "\n", "tot_train, tot_valid, label_train, label_valid=prepDataSets()"]}, {"cell_type": "markdown", "id": "10cde1c2", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='problem_12_1'></a>     \n", "\n", "| [Top](#section_12_0) | [Restart Section](#section_12_1) |"]}, {"cell_type": "markdown", "id": "f319dab4", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 12.1.1</span>\n", "\n", "Why should we build a validation and a training dataset?\n", "\n", "A) So we can test to see if we are overtraining.\\\n", "B) Because half the data is redundant.\\\n", "C) To speed up training."]}, {"cell_type": "markdown", "id": "f7831362", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_12_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P12.2 Machine Learning for the Higgs Boson Search Part II</h2>   \n", "\n", "| [Top](#section_12_0) | [Previous Section](#section_12_1) | [Problems](#problem_12_2) | [Next Section](#section_12_3) |"]}, {"cell_type": "markdown", "id": "3a92cb79", "metadata": {"tags": ["learner", "md", "catsoop_02"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now lets define a very simple network. To start with we are just taking in 1 variable, so we will want to make our network have one input and one output. \n", "\n", "For this we want our output to be between 0 and 1 so we will apply a sigmoid activation. Here is our network below. "]}, {"cell_type": "code", "execution_count": null, "id": "48702f75", "metadata": {"tags": ["learner", "md", "learner_chopped", "catsoop_02"]}, "outputs": [], "source": ["#>>>RUN: P12.2-runcell01\n", "\n", "class MLP(nn.Module):\n", "    def __init__(self):\n", "        super(MLP, self).__init__()\n", "        self.layers = nn.Sequential(\n", "            nn.Linear(1, 2),\n", "            nn.ReLU(),\n", "            nn.Linear(2, 1),\n", "            nn.Sigmoid()\n", "        )\n", "        \n", "    def forward(self, x):\n", "        x = self.layers(x)\n", "        return x\n"]}, {"cell_type": "markdown", "id": "8495e8e2", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='problem_12_2'></a>     \n", "\n", "| [Top](#section_12_0) | [Restart Section](#section_12_2) |"]}, {"cell_type": "markdown", "id": "e8133748", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 12.2.1</span>\n", "\n", "For neural networks, why do we apply Relu activation? Select all that apply:\n", "\n", "A) To speed up training.\\\n", "B) Relu forces a discontinuity in the network, which allows the network to be more expressive.\\\n", "C) Relu introduces non-linearity to the network, enabling it to learn complex patterns.\\\n", "D) Relu improves the network's ability to handle sparse and high-dimensional data.\\\n", "E) Relu reduces the impact of noise in the input data on the network's predictions.\n"]}, {"cell_type": "markdown", "id": "8c7eb6ba", "metadata": {"tags": ["learner", "md", "catsoop_02"]}, "source": ["<h3>Writing Training Code</h3>\n", "\n", "Ok, finally we are going to write a training code for our neural network.  What we are going to do is loop over a number of epochs and then run the network on the full dataset and backpropagate. Additionally, we will dump the loss and accuracy every now and then to make sure the training looks ok. \n", "\n", "As an annoying note, since we are using pytorch, we will have to convert our numpy arrays to pytorch code, this adds a few lines of code to allow for this to happen. "]}, {"cell_type": "code", "execution_count": null, "id": "29e637ca", "metadata": {"tags": ["learner", "md", "learner_chopped", "catsoop_02"]}, "outputs": [], "source": ["#>>>RUN: P12.2-runcell02\n", "\n", "def train(x,y,net,loss_func,opt,nepochs):\n", "    net.train(True)\n", "    for epoch in range(nepochs):\n", "        prediction = net(x)\n", "        opt.zero_grad()\n", "        loss = loss_func(prediction.flatten(),y) \n", "        loss.backward() \n", "        opt.step()\n", "        \n", "        if epoch % 100 == 0: \n", "            #lets split by signal and background\n", "            sig_prediction = prediction[y.flatten()==1]\n", "            bkg_prediction = prediction[y.flatten()==0]\n", "            #now we are going to make a prediction metric for the accuracy\n", "            correct  = sig_prediction[sig_prediction > 0.5].sum().item() #n sig correct \n", "            correct += bkg_prediction[bkg_prediction < 0.5].sum().item() #n bkg corred\n", "            total   = y.size(0)\n", "            accuracy = 100*correct/total\n", "            print('[%d] loss: %.4f acuracy: %.4f' % (epoch + 1, loss.item(),accuracy  ))            \n", "    return\n", "\n", "#delary the model optimizer and loss    \n", "model  = MLP()\n", "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n", "loss_fn    =  nn.BCELoss()\n", "\n", "#now convert everything so that it will work nicely and train\n", "tmp_tot    = torch.tensor(tot_train).float().reshape((len(tot_train),1))\n", "tmp_label  = torch.tensor(label_train).float()\n", "train(tmp_tot,tmp_label,model,loss_fn,optimizer,1000)\n"]}, {"cell_type": "markdown", "id": "396abb53", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 12.2.2</span>\n", "\n", "When you run the preceding code, approximately how many epochs do we need for the training? Select the correct order of magnitude from the options below. Hint: Consider how long it takes the loss to stop changing by large amounts.\n", "\n", "A) 10\\\n", "B) 100\\\n", "C) 1000\\\n", "D) 10000\n", "\n"]}, {"cell_type": "markdown", "id": "7a54ee00", "metadata": {"tags": ["learner", "md", "catsoop_02"]}, "source": ["<h3>Checking with Validation Dataset</h3>\n", "\n", "Now, lets check everything with the validation dataset. We can look at the performance by plotting the reciever operator characteristic (ROC). For comparison, we will also take the same input variable and plot it as well. Additionally, we plot the discriminator for signal and background. "]}, {"cell_type": "code", "execution_count": null, "id": "5bcdf60c", "metadata": {"tags": ["learner", "py", "learner_chopped", "catsoop_02"]}, "outputs": [], "source": ["#>>>RUN: P12.2-runcell03\n", "\n", "from sklearn import metrics\n", "\n", "def drawROC(imodel,idata,ilabel):\n", "    tmp_valid   = torch.tensor(idata).float().reshape((idata.shape))\n", "    tmp_labelv  = torch.tensor(label_valid).float()\n", "    valid_scores = imodel(tmp_valid)\n", "    fpr, tpr, thresholds = metrics.roc_curve(tmp_labelv, valid_scores.detach().numpy())\n", "    fprvar, tprvar, thresholds = metrics.roc_curve(tmp_labelv, -1*idata[:,0])\n", "    plt.plot(fpr,tpr,label=\"full ROC\")\n", "    plt.plot(fprvar,tprvar,'--',label='first var in array')\n", "    plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n", "    plt.legend()\n", "    plt.show()\n", "\n", "    plt.hist(valid_scores[tmp_labelv==0].detach().numpy(),label='ZZ',alpha=0.5)\n", "    plt.hist(valid_scores[tmp_labelv==1].detach().numpy(),label='Higgs',alpha=0.5)\n", "    plt.xlabel(\"disc\")\n", "    plt.ylabel(\"N\")\n", "    plt.legend()\n", "    plt.show()\n", "\n", "drawROC(model,tot_valid,label_valid)"]}, {"cell_type": "markdown", "id": "a260f641", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 12.2.3</span>\n", "\n", "In addition to the ROC we often compute the area under the curve (AUC), and an AUC of 0.5 implies no discrimination. Compute the AUC using `metrics.auc`. What is the value?\n", "\n", "Additionally check the loss on the validation data with `iloss_func()`. Is there a sign of overtraining? To determine whether overtraining has occurred, compare with the loss on the training data, which was `0.6214`.\n", "\n", "Report your answers as a list of two numbers with precision 1e-2: `[AUC, loss]`"]}, {"cell_type": "code", "execution_count": null, "id": "cd709518", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>PROBLEM: P12.2.3\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def computeAUC(imodel,idata,ilabel,iloss_func):\n", "    tmp_valid   = torch.tensor(idata).float().reshape((idata.shape))\n", "    tmp_labelv  = torch.tensor(label_valid).float()\n", "    valid_scores = imodel(tmp_valid)\n", "    fpr, tpr, thresholds = metrics.roc_curve(tmp_labelv, valid_scores.detach().numpy())\n", "    ### Compute AUC here\n", "    print(\"AUC:\",auc)\n", "    ### Compute loss here\n", "    print(\"loss:\",loss)\n", "    \n", "computeAUC(model,tot_valid,label_valid,loss_fn)"]}, {"cell_type": "markdown", "id": "3bf25e49", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["<a name='section_12_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P12.3 Machine Learning for the Higgs Boson Search Part III</h2>   \n", "\n", "| [Top](#section_12_0) | [Previous Section](#section_12_2) | [Problems](#problem_12_3) |"]}, {"cell_type": "markdown", "id": "2f2aecb0", "metadata": {"tags": ["learner", "md", "catsoop_03"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now we want to apply the neural network selection to the data and make a new selection. For good measure, lets compare to the base event selection, and lets plot it. \n", "\n", "The first plot below is the base event selection, established in previous Psets. The second plot is the selection based on our NN."]}, {"cell_type": "code", "execution_count": null, "id": "dbca180d", "metadata": {"scrolled": false, "tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>RUN: P12.3-runcell01\n", "\n", "def evtselnn(lis,iVar=['E1'],nndisc=0.5):   ### Similar as the Function: objsel shown above\n", "    pidvars=['PID1','PID2','PID3','PID4']\n", "    pids=lis[pidvars].values\n", "    leptoncharge=np.sum(pids,1)\n", "    nninputs= torch.tensor(lis[iVar].values).float().reshape(len(lis),len(iVar))\n", "    nnscore = model(nninputs)\n", "    pass_evt = np.logical_and((nnscore.detach().flatten() > nndisc), (leptoncharge == 0))\n", "    lis['PassEvtNN'] = pass_evt\n", "\n", "def setupMCAll(iquery='PassObj == 1 and PassEvt == 1',iVars=['E1'],nndisc=0.5):\n", "    mc_all,mc_sig,mc_bkg_zz,mc_bkg_dy,mc_bkg_tt=loadMC()\n", "    for i,bkg in enumerate(mc_all):\n", "        for j,pro in enumerate(bkg):\n", "            objsel(pro)\n", "            evtsel(pro)\n", "            evtselnn(pro,iVars,nndisc)\n", "            mc_all[i][j] = pro.query(iquery)\n", "    return mc_all\n", "\n", "objsel(data)\n", "evtsel(data)\n", "evtselnn(data)\n", "\n", "#base event selection\n", "sel_data = data.query('PassObj == 1 and PassEvt == 1')\n", "mc_all = setupMCAll('PassObj == 1 and PassEvt == 1')\n", "hist_mc,hist_data=makeAllHists(sel_data,mc_all)\n", "plotHists(hist_mc,hist_data)\n", "\n", "#NN event selection\n", "sel_data = data.query('PassObj == 1 and PassEvt == 1 and PassEvtNN == 1')\n", "mc_all = setupMCAll('PassObj == 1 and PassEvt == 1 and PassEvtNN == 1')\n", "hist_mc,hist_data=makeAllHists(sel_data,mc_all)\n", "plotHists(hist_mc,hist_data)"]}, {"cell_type": "markdown", "id": "ea3c8042", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["<a name='problem_12_3'></a>     \n", "\n", "| [Top](#section_12_0) | [Restart Section](#section_12_3) |"]}, {"cell_type": "markdown", "id": "805a648e", "metadata": {"tags": ["learner", "md", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 12.3.1</span>\n", "\n", "Take a careful look at the preceding plots. What is the neural network doing here? Select only one answer from the following options:\n", "\n", "A) The NN has done nothing.\\\n", "B) The NN reduces the low mass region.\\\n", "C) The NN reduces the high mass region.\\\n", "D) The NN flattens the signal uniformly.\\ \n", "E) The NN clearly enhances the Higgs signal.\\\n", "F) The NN clearly supresses the Higgs signl."]}, {"cell_type": "markdown", "id": "18893df6", "metadata": {"tags": ["learner", "md", "catsoop_03"]}, "source": ["<h3>An Open Ended Task (Question at the End)</h3>\n", "\n", "Let's finally put everything together and train with more variables. This will be slightly open-ended, and we only ask one question at the end, in order to consider if you can find any improvements. **We encourage you to share your work on the discussion forum and communicate with your peers about what you have tried.**\n", "\n", "In what follows you will:\n", "\n", "- Construct your own NN discriminator with variables you like (for instance, in the cell below, we provide an option to use many more variables).\n", "- Define and train the network\n", "- Examine the ROC\n", "- Plot the histogram\n", "- Compute the significance"]}, {"cell_type": "code", "execution_count": null, "id": "4200896d", "metadata": {"tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>RUN: P12.3-runcell02\n", "\n", "vars  =['px1','py1','eta1','phi1','PID1']\n", "vars +=['px2','py2','eta2','phi2','PID2']\n", "vars +=['px3','py3','eta2','phi3','PID3']\n", "vars +=['px4','py4','eta2','phi4','PID4']\n", "\n", "tot_train, tot_valid, label_train, label_valid=prepDataSets(vars)\n", "print(tot_train.shape)"]}, {"cell_type": "markdown", "id": "f4119a45", "metadata": {"tags": ["md", "learner", "learner_chopped", "catsoop_03"]}, "source": ["<h3>Define the Network and Train</h3>\n", "\n", "Construct your own neural network architecture and train you neural network. **Write your code in the following cells.**\n", "\n", "See the solution of Problem 12.3.2 for an example NN that we defined."]}, {"cell_type": "code", "execution_count": null, "id": "6baefe81", "metadata": {"tags": ["py", "draft", "learner_chopped"]}, "outputs": [], "source": ["#>>>RUN: P12.3-runcell03\n", "# Use this cell for drafting your solution (if desired)\n", "\n", "#Your NN construction code\n", "model = ## add code here\n", "\n", "#Lets just take code from above\n", "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n", "loss_fn   =  nn.BCELoss()\n", "tmp_tot    = torch.tensor(tot_train).float()\n", "tmp_label  = torch.tensor(label_train).float()\n", "train(tmp_tot,tmp_label,model,loss_fn,optimizer,500)"]}, {"cell_type": "markdown", "id": "69e84dec", "metadata": {"tags": ["md", "learner", "catsoop_03"]}, "source": ["<h3>Examine the ROC</h3>\n", "\n", "Now run your own selection with your updated neural network, and look at the ROC, be sure to cut on the discriminator value that is reasonable."]}, {"cell_type": "code", "execution_count": null, "id": "d7aca24d", "metadata": {"tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>RUN: P12.3-runcell04\n", "\n", "drawROC(model,tot_valid,label_valid)\n", "objsel(data)\n", "evtsel(data)\n", "evtselnn(data,vars,nndisc=0.5)\n", "sel_data = data.query('PassObj == 1 and PassEvt == 1 and PassEvtNN == 1')\n", "mc_all = setupMCAll('PassObj == 1   and PassEvt == 1 and PassEvtNN == 1',vars,nndisc=0.5)"]}, {"cell_type": "markdown", "id": "354cb990", "metadata": {"tags": ["md", "learner", "catsoop_03"]}, "source": ["<h3>Plot the Histogram</h3>\n", "\n", "Let's make a plot and see how it looks. Where is the neural network removing events?"]}, {"cell_type": "code", "execution_count": null, "id": "d0e8a1d1", "metadata": {"tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>RUN: P12.3-runcell05\n", "\n", "hist_mc,hist_data=makeAllHists(sel_data,mc_all)\n", "plotHists(hist_mc,hist_data)"]}, {"cell_type": "markdown", "id": "eb9dd87e", "metadata": {"tags": ["md", "learner", "catsoop_03"]}, "source": ["<h3>Compute the Significance</h3>\n", "\n", "Finally, compute the significance using the code that we defined previously. For this, we will have to rebuild the signal and background splines from the last Pset, and then look at the variation over mass. "]}, {"cell_type": "code", "execution_count": null, "id": "9703c6ce", "metadata": {"scrolled": false, "tags": ["py", "learner", "learner_chopped", "catsoop_03"]}, "outputs": [], "source": ["#>>>RUN: P12.3-runcell06\n", "\n", "sig_interpolate,bkg_interpolate=setupSpline(hist_mc)\n", "chi2bkg=fithistograms(125,hist_data,shiftbkg)\n", "mhscan,NLLs,pscan=massscan(sigbkg,plot=True)\n", "\n", "mass(mhscan,NLLs,124,130)"]}, {"cell_type": "markdown", "id": "98e5196f", "metadata": {"tags": ["md", "learner", "learner_chopped"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 12.3.2</span>\n", "\n", "How does the Higgs significance using the new NN compare to our earlier discoveries?\n", "\n", "A) This fit shows a more significant Higgs peak.\\\n", "B) This fit shows an equally or less significant Higgs peak."]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}