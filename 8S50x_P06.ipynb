{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9aea549",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<hr style=\"height: 1px;\">\n",
    "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "<h1>Guided Problem Set 6: Matched Filtering Part I - Time Domain </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee4bd26",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='section_6_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P6.0 Overview</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce3aeb",
   "metadata": {
    "tags": [
     "md",
     "learner"
    ]
   },
   "source": [
    "<h3>Navigation</h3>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_1\">P6.1 What is Matched Filtering?</a>\n",
    "        </td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_1\">P6.1 Problems</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_2\">P6.2 Fitting in the Time Domain: Part I</a>\n",
    "        </td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_2\">P6.2 Problems</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_3\">P6.3 Fitting in the Time Domain: Part II</a>\n",
    "        </td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_3\">P6.3 Problems</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_6_4\">P6.4 Sweeping the Time Window</a>\n",
    "        </td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_6_4\">P6.4 Problems</a></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189f628d",
   "metadata": {
    "tags": [
     "learner",
     "catsoop_00",
     "md"
    ]
   },
   "source": [
    "<h3>Summary</h3>\n",
    "\n",
    "**P6.1 What is Matched Filtering**\n",
    "<ul>\n",
    "    <li>text needed</li>\n",
    "</ul>\n",
    "\n",
    "**P6.2 Fitting in the Time Domain: Part I**\n",
    "<ul>\n",
    "    <li>text needed</li>\n",
    "</ul>\n",
    "\n",
    "**P6.3 Fitting in the Time Domain: Part II**\n",
    "<ul>\n",
    "    <li>text needed</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "**P6.4 Sweeping the Time Window**\n",
    "<ul>\n",
    "    <li>text needed</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33028e3",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Importing Libraries and Data</h3>\n",
    "\n",
    "Before beginning, run the cell below to import the relevant libraries for this notebook. \n",
    "Optionally, set the plot resolution and default figure size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409350fe",
   "metadata": {
    "tags": [
     "learner",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "!pip install lmfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2897cb9",
   "metadata": {
    "tags": [
     "learner",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from lmfit import Model, Parameters\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chisquare\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "#set plot resolution\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#set default figure size\n",
    "plt.rcParams['figure.figsize'] = (9,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e394c30f",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='section_6_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P6.1 What is Matched Filtering?</h2>    \n",
    "\n",
    "| [Top](#section_6_0) | [Previous Section](#section_6_0) | [Problems](#problems_6_1) | [Next Section](#section_6_2) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0308ab44",
   "metadata": {
    "tags": [
     "learner",
     "catsoop_01",
     "md"
    ]
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "The purpose of matched filtering is to scan big data sets looking for some kind of signal. LIGO does this to look for gravitational waves in their strain data. Matched filtering is also done in many other fields.\n",
    "\n",
    "The purpose is usually to create some kind of plot of signal to noise ratio (SNR) over your data. For LIGO, this is a 2D plot with time on the x axis and SNR on the y axis. If you're looking for point sources in astrophysical telescope data, for example, this is an image plot with right ascention and declination as the axes and SNR shown in the image.\n",
    "\n",
    "Signals look like large spikes in the SNR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40824af5",
   "metadata": {
    "tags": [
     "learner",
     "catsoop_01",
     "md"
    ]
   },
   "source": [
    "To make this exercise useful to you in the LIGO project, we'll make a model signal that looks kind of like a black hole waveform. Run the below code to load the waveform and plot an example. (This is nearly the same function as was used in recitation 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6d4b5",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "catsoop_01"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0x98a09fe)\n",
    "\n",
    "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
    "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
    "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
    "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
    "    return amplitude * np.cos(omega * (x-time))\n",
    "\n",
    "LAMBDA_PLUS_TRUE = 1.0\n",
    "LAMBDA_MINUS_TRUE = 4\n",
    "MAX_AMP_TRUE = 1.2\n",
    "OMEGA_0_TRUE = 3.0\n",
    "OMEGA_MAX_TRUE = 6.0\n",
    "OMEGA_SIGMA_TRUE = 4.0\n",
    "TIME_TRUE = 50.0\n",
    "\n",
    "xi = np.linspace(TIME_TRUE-15, TIME_TRUE+5, 200)\n",
    "true_yi = complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
    "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
    "\n",
    "plt.plot(xi, true_yi)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da98577",
   "metadata": {
    "tags": [
     "learner",
     "catsoop_01",
     "md"
    ]
   },
   "source": [
    "Let's make some fake data. We'll simulate \"noise\" as ten sinusoids of varying frequency, phase, and amplitude added together, and superimpose a merger signal at $t=0$. Make sure you take your time to read the code and understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b3a30",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "catsoop_01"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "np.random.seed(908)\n",
    "\n",
    "NUMBER_SINES_TO_ADD = 10\n",
    "\n",
    "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n",
    "    # equal to the maximum amplitude of the signal.\n",
    "\n",
    "sample_spacing = 0.1\n",
    "xi = np.arange(-128, 128, sample_spacing)#times\n",
    "yi = np.zeros_like(xi)#data\n",
    "\n",
    "#Adding Noise\n",
    "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
    "    yi += amplitude * np.sin(phase + freq * xi)\n",
    "   \n",
    "#Adding Data\n",
    "yi += complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
    "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(xi, yi)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b629bab",
   "metadata": {
    "tags": [
     "learner",
     "catsoop_01",
     "md"
    ]
   },
   "source": [
    "Our goal is to find the signal in this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcd7cd",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='problems_6_1'></a>     \n",
    "\n",
    "| [Top](#section_6_0) | [Restart Section](#section_6_1) | [Next Section](#section_6_2) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925de8e1",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.1.1</span>\n",
    "\n",
    "In this problem we will generate some noise and create SNR (signal to noise ratio) plots in order to identify the time at which a signal exists. Since we already know the signal and the noise seperately, we can implement a naive approach to finding the time which the signal exists where we will simply take the time location of the maximum of the SNR as the time where the signal event occurs. Your goal is to explore how well this crude method estimates the signal event.\n",
    "\n",
    "First, generate some noise composed of 1,000 sines with frequencies randomly taken from a normal distribution with mean at .8 and standard deviation of 5, phases taken from a random uniform distribution ranging from 0 to $2\\pi$, and amplitudes set so that the sum of all the noise amplitudes is on average equal to the maximum amplitude of the signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eba598",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "MAX_AMP_TRUE = 1.2\n",
    "SAMPLE_SPACING = 0.1\n",
    "NUMBER_SINES_TO_ADD = 1000\n",
    "\n",
    "xi = np.arange(0, 128, SAMPLE_SPACING)#times\n",
    "\n",
    "def generate_noise(xi):\n",
    "  np.random.seed(908)\n",
    "  yi_noise = np.zeros_like(xi)\n",
    "\n",
    "  noise_frequencies = 0 #YOUR CODE HERE\n",
    "  noise_phases = 0 #YOUR CODE HERE\n",
    "  noise_amplitudes = 0 #YOUR CODE HERE\n",
    "\n",
    "  #Adding Noise\n",
    "  for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
    "      yi_noise += amplitude * np.sin( phase + freq * xi)\n",
    "\n",
    "  return yi_noise\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.plot(xi, generate_noise(xi))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dc2f2e",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.1.2</span>\n",
    "\n",
    "Now, we would like to show that by taking the region with maximum strain, we can find the signal. As a first check, we want to check that we can get an injected signal by taking the maximum in the range. Furthermore, we want to check that the injected signal has a maximum time consistent with the injected time. This is a test of the response of the injected wave. \n",
    "\n",
    "Create a set of 50 signals of the form shown earlier with the below parameters. Each signal should correspond with each whole second in the range [50, 100) where the corresponding second is the `TRUE_TIME` of the signal (i.e., you should have one signal occuring at t=50, one at t=51, one at t=52, etc.).\n",
    "\n",
    "For each signal, inject it in the noise and try to find the time at which the injection happens by taking the max devitation. Lastly, make a plot of the true (injected) time, vs the max SNR time. You will notice the scale option on the function `get_Max_times`; this option can be added to rescale the size of the signal before it gets injected. \n",
    "\n",
    "HINT: take a look at `np.argmax()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71058141",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "LAMBDA_PLUS_TRUE = 1.0\n",
    "LAMBDA_MINUS_TRUE = 4\n",
    "MAX_AMP_TRUE = 1.2\n",
    "OMEGA_0_TRUE = 3.0\n",
    "OMEGA_MAX_TRUE = 6.0\n",
    "OMEGA_SIGMA_TRUE = 4.0\n",
    "\n",
    "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
    "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
    "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
    "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
    "    return amplitude * np.cos(omega * (x-time))\n",
    "\n",
    "def get_max_times(xi, yi_noise, true_times,scale=1.0,iCheck=False):\n",
    "    time_of_maximums = []\n",
    "\n",
    "    for t in true_times:\n",
    "\n",
    "        yi_signal = #YOUR CODE HERE\n",
    "        yi_test_noise = #YOUR CODE HERE\n",
    "        SNR = #YOUR CODE HERE\n",
    "        \n",
    "        time_of_maximums.append(xi[np.argmax(SNR)])\n",
    "        \n",
    "        if int(t) == 75 and iCheck:\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Strain\")\n",
    "            plt.plot(xi,yi_test_noise)\n",
    "            plt.plot(xi,yi_signal)\n",
    "            plt.show()\n",
    "        \n",
    "    return time_of_maximums\n",
    "\n",
    "true_times = np.linspace(50, 100, 50)\n",
    "xi = np.arange(0, 128, SAMPLE_SPACING)\n",
    "yi_noise = generate_noise(xi)\n",
    "\n",
    "plt.plot(true_times, get_max_times(xi, yi_noise, true_times), label = 'naive model')\n",
    "plt.xlabel('True Times (s)')\n",
    "plt.ylabel('Predicted Times (s)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e863b4",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.1.3</span>\n",
    "\n",
    "For each of the 50 signals, plot the time at which you estimated the signal to have occured against the time at which the signal acually occured (true time on x-axis, estimated time on y-axis). Also plot the line y=x on the plot (what a perfect algorithm would look like). What does the crude method look like as compared to a perfect algorithm? Select the best answer below:\n",
    "\n",
    "- Crude method fits exactly to ideal algorithm\n",
    "\n",
    "- Crude method mostly gets the time at which the signal event occurs and occationally overestimates/understimates.\n",
    "\n",
    "- Crude method largely underestimates the time at which the signal event occurs and occationally overestimates.\n",
    "\n",
    "- Crude method largely overestimates the time at which the signal event occurs and occationally underestimately.\n",
    "\n",
    "- Crude method always underestimates the time at which the signal event occurs.\n",
    "\n",
    "- Crude method always overestimates the time at which the signal event occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e08fa",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0e8f8b",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.1.4</span>\n",
    "\n",
    "Finally, now scale the algorithm down by a factor of 20, what happens to the crude method? Select the best answer below:\n",
    "\n",
    "- Crude method fits exactly to ideal algorithm\n",
    "\n",
    "- Crude method largely underestimates the time at which the signal event occures and occationally overestimates.\n",
    "\n",
    "- Crude method largely overestimates the time at which the signal event occures and occationally underestimately.\n",
    "\n",
    "- Crude method always underestimates the time at which the signal event occures.\n",
    "\n",
    "- Crude method almost always doesn't work. \n",
    "\n",
    "- Crude method doesn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb318d7a",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886eded2",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='section_6_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P6.2 Fitting in the Time Domain: Part I</h2>    \n",
    "\n",
    "| [Top](#section_6_0) | [Previous Section](#section_6_1) | [Problems](#problems_6_2) | [Next Section](#section_6_3) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a0f1a",
   "metadata": {
    "tags": [
     "learner",
     "catsoop_02",
     "md"
    ]
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "In this section you will solve a series of problems which uses a more sophisticated algorithm, called matched filtering, for finding the time at which the signal event occured. This is one of the more difficult problems of the course.\n",
    "\n",
    "Matched filtering in the time domain is probably conceptually the easiest approach to matched filtering. We will perform a fit of the model function to the data, forcing the model function to assume a time of merger of $t$, then plot the quality of the fit as a function of $t$. We expect a very good fit quality when $t$ is close to the true time $t=0$, and otherwise we expect poor fits.\n",
    "\n",
    "First, let's regenerate the data (same code as in first section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa99f9",
   "metadata": {
    "tags": [
     "learner",
     "py",
     "catsoop_02"
    ]
   },
   "outputs": [],
   "source": [
    "np.random.seed(0x98a09fe)\n",
    "\n",
    "def complicated_model_fn(x, time, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n",
    "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x - time, 0)**2 / omega_sigma)) + omega_0\n",
    "    lambdas = np.array([lambda_plus if xvalue > time else lambda_minus for xvalue in x])\n",
    "    amplitude = max_amp * np.exp(-abs(x - time) / lambdas)\n",
    "    return amplitude * np.cos(omega * (x-time))\n",
    "\n",
    "def simple_fn(x,decay,constant,amplitude):\n",
    "    return amplitude*np.exp(-1*x*decay)+constant\n",
    "\n",
    "Model(simple_fn)\n",
    "\n",
    "LAMBDA_PLUS_TRUE = 1.0\n",
    "LAMBDA_MINUS_TRUE = 4\n",
    "MAX_AMP_TRUE = 1.2\n",
    "OMEGA_0_TRUE = 3.0\n",
    "OMEGA_MAX_TRUE = 6.0\n",
    "OMEGA_SIGMA_TRUE = 4.0\n",
    "TIME_TRUE = 50.0\n",
    "\n",
    "xi = np.linspace(TIME_TRUE-15, TIME_TRUE+5, 200)\n",
    "true_yi = complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
    "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
    "\n",
    "NUMBER_SINES_TO_ADD = 10\n",
    "\n",
    "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n",
    "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n",
    "    # equal to the maximum amplitude of the signal.\n",
    "\n",
    "plt.plot(xi, true_yi)\n",
    "plt.title(\"True Signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.show()\n",
    "\n",
    "sample_spacing = 0.1\n",
    "xi = np.arange(-128, 128, sample_spacing)#times\n",
    "yi = np.zeros_like(xi)#data\n",
    "\n",
    "#Adding Noise\n",
    "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n",
    "    yi += amplitude * np.sin(phase + freq * xi)\n",
    "\n",
    "#Adding Data\n",
    "signal= complicated_model_fn(xi, TIME_TRUE, LAMBDA_PLUS_TRUE, LAMBDA_MINUS_TRUE, MAX_AMP_TRUE,\n",
    "                               OMEGA_0_TRUE, OMEGA_MAX_TRUE, OMEGA_SIGMA_TRUE)\n",
    "yi+=signal\n",
    "\n",
    "plt.plot(xi, yi)\n",
    "plt.plot(xi, signal)\n",
    "plt.title(\"Signal plus noise\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(xi, yi)\n",
    "plt.plot(xi, signal)\n",
    "plt.title(\"Signal plus noise\")\n",
    "plt.xlim(35,55)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b988556",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='problems_6_2'></a>     \n",
    "\n",
    "| [Top](#section_6_0) | [Restart Section](#section_6_2) | [Next Section](#section_6_3) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884b30b",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.2.1</span>\n",
    "\n",
    "We'll need to cut the data to perform the fit. How much time before and after $t$ would you like to fit over? We really only need to consider the region where the signal is larger than the noise. In practice this is something we could systematcially calculate on the fly, given the noise and signal size, for instance by analyzing the plot that we generated. Since this is a little subjective, read the guidance below to choose an appropriate window.\n",
    "\n",
    "In what follows, only consider a 7-10 second window, as this will include enough data to make our fits converge, but will still give little enough data that the fits converge the fastest. Furthermore, this window need not be symetric, as much of the signal lies before the true time with only a little bit of signal left after the time of the event. Therefore, `t_before` > `t_after`.\n",
    "\n",
    "With these conditions, one possible choice for `[t_before, t_after]` is `[5,2]`. What is another acceptable answer, given the constraints that we outlined?\n",
    "\n",
    "Enter your answer as a list, formatted as `[t_before, t_after]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d0605",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.2.2</span>\n",
    "\n",
    "We will make a function that creates an `LMFIT` `Model` and `Parameters` instance for the complicated model `complicated_model_fn` with starting time `t` and parameters constrained by the dictionary `params_min_max`. Specifically, this function will force the time of the signal to appear at time `t` and will randomly seed the starting points of the parameters that are used, within the given parameter ranges. Call this function `model_and_random_parameters(t)`.\n",
    "\n",
    "Your task is to write a function that seeds the starting points of parameters randomly, such that each parameter `p` takes on a uniformly distributed random value within the range defined by `p_min` and `p_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bbd85",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "from lmfit import Model, Parameters\n",
    "    \n",
    "    \n",
    "def get_param_random_value(p_min,p_max):\n",
    "    #get a uniformly distributed random value between p_min and p_max\n",
    "    #return a float\n",
    "    return #YOUR CODE HERE\n",
    "\n",
    "\n",
    "params_min_max = {\n",
    "    'lambda_plus': (0.1, 5),\n",
    "    'lambda_minus': (0.1, 5),\n",
    "    'max_amp': (0, 2),\n",
    "    'omega_0': (0, 5),\n",
    "    'omega_max': (0, 10),\n",
    "    'omega_sigma': (0, 5)\n",
    "}\n",
    "\n",
    "def model_and_random_parameters(t):\n",
    "    model = Model(complicated_model_fn)\n",
    "    params = Parameters()\n",
    "    params.add('time', value=t, vary=False)\n",
    "    for p, (p_min, p_max) in params_min_max.items():\n",
    "        value = get_param_random_value(p_min,p_max)\n",
    "        params.add(p, min=p_min, max=p_max, value=value)\n",
    "    return model, params\n",
    "\n",
    "\n",
    "#TEST EXAMPLE: SHOULD = 1.51166\n",
    "t=0.1\n",
    "np.random.seed(1)\n",
    "print(model_and_random_parameters(t)[1].get('omega_0').value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a3556b",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.2.3</span>\n",
    "\n",
    "Now, make a function that fits the model created in the previous problem and outputs the fit result. Remember that we only want to look at a specific part of the data when we fit, namely the range `(t-t_before, t+t_after)`, where `t` is the specific time at which we want to look for the signal. Use the values `t_before = 5` and `t_after = 2`.\n",
    "\n",
    "HINT: to do this, the function `np.where()` may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98bfdc",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "import lmfit\n",
    "\n",
    "#THE WINDOW MUST BE [5,2] FOR YOUR ANSWER TO MATCH EXPECTED VALUES\n",
    "t_before = 5\n",
    "t_after = 2\n",
    "\n",
    "\n",
    "def get_signal_indices(xi, t, t_before, t_after):\n",
    "    #use np.where() to return a 1D the relevant indices\n",
    "    #note, the result of np.where() will be a tuple\n",
    "    return #YOUR CODE HERE\n",
    "\n",
    "def fit_once(xi, yi, t, t_before, t_after):\n",
    "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
    "    data_x = xi[data_indices]\n",
    "    data_y = yi[data_indices]\n",
    "    model, params = model_and_random_parameters(t)    \n",
    "    result = model.fit(data_y, params, x=data_x)\n",
    "    return result\n",
    "\n",
    "result = fit_once(xi, yi, TIME_TRUE, t_before, t_after)\n",
    "result.plot();\n",
    "\n",
    "#print(\"Fit chi2 value: \", result.chisqr)\n",
    "#print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812323f3",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.2.4</span>\n",
    "\n",
    "Run the fit multiple times and print the $\\chi^{2}$ value and $\\chi^{2}$ probability using the following lines of code.\n",
    "\n",
    "<pre>\n",
    "print(\"Fit chi2 value: \", result.chisqr)\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))\n",
    "</pre>\n",
    "\n",
    "What is the lowest $\\chi^{2}$ value that you obtain, and corresponding $\\chi^{2}$ probability?\n",
    "\n",
    "Enter your answer as a list of numbers `[chi2, chi2_prob]` with precision 1e-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378f2e9",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.2.5</span>\n",
    "\n",
    "Let's consider whether the $\\chi^{2}$ of the fit is a reasonable number. What does the $\\chi^{2}$ probability say about the fit? Choose the best answer from the following options:\n",
    "\n",
    "- The fit is perfect! This is because our model is perfect. Our job is done.\n",
    "- The fit is perfect, which means we should consider carefully the assumptions we have made.\n",
    "- The fit is okay, and we can do no better.\n",
    "- The fit is terrible, so we should adjust our model or the range of data that we are fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a178b2b",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "import scipy.stats as stats\n",
    "\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b43d78",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='section_6_3'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P6.3 Fitting in the Time Domain: Part II</h2>    \n",
    "\n",
    "| [Top](#section_6_0) | [Previous Section](#section_6_2) | [Problems](#problems_6_3) | [Next Section](#section_6_4) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3549dd",
   "metadata": {
    "tags": [
     "learner",
     "md",
     "catsoop_03"
    ]
   },
   "source": [
    "<h3>Weighted Fitting</h3>\n",
    "\n",
    "The uncertainties are overesimated, but why? The real issue is that our fit so far has not taken into account the uncertainties correctly. To do that, we need to do a weighed $\\chi^{2}$ fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2249bf51",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='problems_6_3'></a>     \n",
    "\n",
    "| [Top](#section_6_0) | [Restart Section](#section_6_3) | [Next Section](#section_6_4) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ad9f2",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.3.1</span>\n",
    "\n",
    "Take the above fit, and repeat it but taking the uncertainties to a value of $\\sigma=0.2$. To do this, you will have run a weighted fit with `lmfit` by setting an array of weights. Note, the weights in `lmfit` are designed so that $w=1/\\sigma$, leading to the following:\n",
    "\n",
    "$$\\chi^{2} = \\sum_{i}\\frac{(f(x_{i})-f(x))^{2}}{\\sigma_{i}^{2}}$$\n",
    "\n",
    "From this, now what is the $\\chi^{2}$ probability corresponding to the lowest $\\chi^{2}$ value ? Enter your answer as a number with precision 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dbf2c5",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "import lmfit\n",
    "\n",
    "def fit_once_weighted(xi, yi, t, t_before, t_after, weight=1.0):\n",
    "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
    "    data_x = xi[data_indices]\n",
    "    data_y = yi[data_indices]\n",
    "    \n",
    "    weights = #YOUR CODE HERE\n",
    "    \n",
    "    model, params = model_and_random_parameters(t)\n",
    "    result = model.fit(data_y, params, x=data_x,weights=weights)\n",
    "    return result\n",
    "\n",
    "\n",
    "unc=0.2\n",
    "result = fit_once_weighted(xi, yi, TIME_TRUE, t_before, t_after,1./unc)\n",
    "\n",
    "result.plot();\n",
    "print(\"Fit chi2 value: \", result.chisqr)\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea61cff",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.3.2</span>\n",
    "\n",
    "Finally, we should come up with a strategy to compute the uncertainty of our points. Uncertainty is often defined by how accurate you are trying to model your dataset. With LIGO data, this is a difficult question, since much of the wiggles from the \"Noise\" are actually understood as oscillations at certain frequencies. \n",
    "\n",
    "In this problem, we are going to make the statement, that we do not wish to model the noise, and we would like to have our uncertainty reflect the average RMS of our noisy, signal-free data. \n",
    "\n",
    "Take the dataset above, and compute the standard deviation of the signal free noise, then repeat the fit. What $\\chi^{2}$ probability do you get? Enter your answer as a number with precision 1e-3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c951269",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "import lmfit\n",
    "\n",
    "def get_noise_indices(xi, t, t_before, t_after):\n",
    "    return #YOUR CODE HERE\n",
    "    \n",
    "\n",
    "def noise(xi, yi, t, t_before, t_after):\n",
    "    data_indices = get_noise_indices(xi, t, t_before, t_after)\n",
    "    data_y = yi[data_indices]\n",
    "    return np.std(data_y)\n",
    "\n",
    "unc=noise(xi, yi, TIME_TRUE, t_before, t_after)\n",
    "result = fit_once_weighted(xi, yi, TIME_TRUE, t_before, t_after,1./unc)\n",
    "result.plot();\n",
    "print(\"unc value: \", unc)\n",
    "print(\"Fit chi2 value: \", result.chisqr)\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfab8ae",
   "metadata": {
    "tags": [
     "md",
     "catsoop_03",
     "learner"
    ]
   },
   "source": [
    "<h3>Correlations</h3>\n",
    "\n",
    "Our fit is, in some sense, still too good! Why is this the case? Well, what is happening in this case is that our fit function is fitting the noise as well. This is partly a feature of fitting time series data, where the points are correlated with one another, and the reality is that $\\chi^{2}$ assumes points randomly fluctuate with each point independent of the previous, whereas here the consecutive points are correlated (i.e., a point will be low if previous point was lower if the noise fluctuated low).\n",
    "\n",
    "To get a better estimate of the quality of the fit, we can imagine taking every other point or trying to compute the point to point variation, by taking the difference between consecutive points, or even points that are a little farther away. The larger the delta-t of our RMS, the less assumptions we are making about our ability to model background noise. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91755e",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    ">#### Follow-up 6.3.2a (ungraded)\n",
    ">\n",
    ">Try running the cells below. In the first case, nearest-neighbor data are averaged and the data are fit again. In the second case, the noise is estimated from differences in points that are 2 time-steps away. Do you think these are reasonable attempts to account for the correlated nature of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b55c56",
   "metadata": {
    "tags": [
     "learner",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "#Computing uncertainty: merging bins\n",
    "\n",
    "xi_old = xi.copy()\n",
    "yi_old = yi.copy()\n",
    "xi_new = np.array([ 0.5*(xi_old[2*i]+xi_old[2*i+1]) for i in range(len(xi_old)//2) ])\n",
    "yi_new = np.array([ 0.5*(yi_old[2*i]+yi_old[2*i+1]) for i in range(len(yi_old)//2) ])\n",
    "\n",
    "\n",
    "uncout=noise(xi_new, yi_new, TIME_TRUE, t_before, t_after)\n",
    "result = fit_once_weighted(xi_new, yi_new, TIME_TRUE, t_before, t_after,1./uncout)\n",
    "result.plot();\n",
    "print(\"unc value: \", uncout)\n",
    "print(\"Fit chi2 value: \", result.chisqr)\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dde408",
   "metadata": {
    "tags": [
     "learner",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "\n",
    "#Computing uncertainty: points 2 samples away\n",
    "\n",
    "def noise_deltat(xi, yi, t, t_before, t_after, dt=2):#dt is the size distance of the samples\n",
    "    data_indices = get_noise_indices(xi, t, t_before, t_after)\n",
    "    #print(data_indices[0][:-dt],data_indices[0][dt:])\n",
    "    data_y = yi[data_indices[0][:-dt]]-yi[data_indices[0][dt:]]\n",
    "    return np.std(data_y)\n",
    "\n",
    "uncout=noise_deltat(xi_old, yi_old, TIME_TRUE, t_before, t_after)\n",
    "result = fit_once_weighted(xi_old, yi_old, TIME_TRUE, t_before, t_after,1./uncout)\n",
    "result.plot();\n",
    "print(\"unc value: \", uncout)\n",
    "print(\"Fit chi2 value: \", result.chisqr)\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d18a81",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='section_6_4'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P6.4 Sweeping the Time Window</h2>   \n",
    "\n",
    "| [Top](#section_6_0) | [Previous Section](#section_6_3) | [Problems](#problems_6_4) | [Next Section](#section_6_5) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c32c71",
   "metadata": {
    "tags": [
     "catsoop_04",
     "learner",
     "md"
    ]
   },
   "source": [
    "<h3>Fitting Using Multiprocessing</h3>\n",
    "\n",
    "From the above analysis, we see that an uncertainty of 0.18 is more reasonable. This was found for `dt=2`, which should limit the assumptions we are making about the nature of the background noise. Go back and try the follow-up exercises if you have not done so already!\n",
    "\n",
    "Let's redefine `fit_once` using this uncertainty. Run the code below several times. Does it always find the lowest $\\chi^2$ value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e740a89",
   "metadata": {
    "scrolled": false,
    "tags": [
     "py",
     "learner",
     "catsoop_04"
    ]
   },
   "outputs": [],
   "source": [
    "#From the above analysis, we see that an uncertainty of 0.18 is more reasonable.\n",
    "#This was found for deltat = 2, which should limit that assumptions we are making\n",
    "#about the nature of the background noise\n",
    "\n",
    "#Let's try using this uncertainty\n",
    "\n",
    "\n",
    "def fit_once_new(t, weight=1./0.18):\n",
    "    data_indices = get_signal_indices(xi, t, t_before, t_after)\n",
    "    data_x = xi[data_indices]\n",
    "    data_y = yi[data_indices]\n",
    "    weights = np.ones(len(data_x))*weight\n",
    "    model, params = model_and_random_parameters(t)\n",
    "    result = model.fit(data_y, params, x=data_x,weights=weights)\n",
    "    return result\n",
    "\n",
    "\n",
    "result = fit_once_new(TIME_TRUE)\n",
    "result.plot();\n",
    "print(\"Fit chi2 value: \", result.chisqr)\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efff91",
   "metadata": {
    "tags": [
     "catsoop_04",
     "md",
     "learner"
    ]
   },
   "source": [
    "Now, instead of `fit_once_new`, we'll use a new function called `fit`, which runs `fit_once_new` multiple times and outputs the best (lowest $\\chi^2$) result.\n",
    "\n",
    "To do this, we will use a package you may not have been exposed to yet: `multiprocessing`. The idea is to run these fits simultaneously to make our code run quicker. The way we do this is by using the `pool.map` function in order to make an list of results called `results`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f50bb",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "<a name='problems_6_4'></a>     \n",
    "\n",
    "| [Top](#section_6_0) | [Restart Section](#section_6_4) | [Next Section](#section_6_5) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef062981",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.4.1</span>\n",
    "\n",
    "Consider the code below, where multiprocessing is already implemented. All you have to do is find the best result in the list and return it.\n",
    "\n",
    "Code the rest of the `fit` function. What is the lowest $\\chi^2$ value and corresponding probability? Enter your answer as a list of numbers `[chi2, chi2_prob]` with precision 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7ac66",
   "metadata": {
    "scrolled": false,
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "def get_min_result(results):\n",
    "    min_result = None\n",
    "    min_chisq = None\n",
    "    #for each result in results, set a new min_result and min_chisq\n",
    "    #if result.chisqr is less than the currently stored value\n",
    "    \n",
    "    #YOUR CODE HERE\n",
    "    \n",
    "    return min_result\n",
    "\n",
    "NUM_FITS = 6\n",
    "\n",
    "def fit(t, pool):\n",
    "    results = pool.map(fit_once_new, np.full(NUM_FITS, t))\n",
    "    min_result = get_min_result(results)\n",
    "    return min_result\n",
    "\n",
    "with Pool(6) as pool:   #'6' here refers to the number of mutliprocessing jobs\n",
    "    result = fit(TIME_TRUE, pool)\n",
    "\n",
    "result.plot();\n",
    "print(\"Fit chi2 value: \", result.chisqr)\n",
    "print(\"Fit chi2 probability: \",1-stats.chi2.cdf(result.chisqr,result.nfree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4f0ce",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.4.2</span>\n",
    "\n",
    "Next, we want to see what the fits look like for different `t` values. Call `fit` for values of $t \\in [-100, 100]$, where the $t$ values are separated by $\\Delta t \\sim 1 \\text{s}$. Store the results in an array named `results`. The multiprocessing parts have been done for you, just run the code (this could take a little while).\n",
    "\n",
    "How long does it take to do this? (pick the closest answer)\n",
    "\n",
    "A. .01 seconds\n",
    "\n",
    "B. 1 second\n",
    "\n",
    "C. 5 minutes\n",
    "\n",
    "D. 5 hours (if this is the answer you pick **something is wrong**)\n",
    "\n",
    "E. 10 days (if this is the answer you pick **something is wrong**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25836f4",
   "metadata": {
    "tags": [
     "py",
     "learner"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>RUN\n",
    "%%time\n",
    "\n",
    "results = []\n",
    "delta_t = 1\n",
    "ts = np.arange(-100, 100, delta_t)\n",
    "\n",
    "with Pool(NUM_FITS) as pool:\n",
    "    for t in ts:\n",
    "        if t % 10 == 0: print(t)\n",
    "        results.append(fit(t, pool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32b8600",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 6.4.3</span>\n",
    "\n",
    "Now we need to find out for which $t$ value we get a fit that is most likely to be our signal. One way of figuring this out is by looking for which fit has the largest `max_amp` parameters, as the signal will have a higher max amplitude than the surrounding noise.\n",
    "\n",
    "Plot `max_amp` as a function of $t$ given the `results` you just calculated. Find the value of $t$ which has the largest `max_amp` and plot the corresponding fit result.\n",
    "\n",
    "Does the fit look like it could be the signal we're looking for? If yes, then enter below at what value of $t$ this was. If not, keep searching through the next highest `max_amp` values till you get something that may be signal and answer that $t$ value below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c5e8b",
   "metadata": {
    "tags": [
     "draft",
     "py"
    ]
   },
   "outputs": [],
   "source": [
    "#>>>PROBLEM\n",
    "# Use this cell for drafting your solution (if desired),\n",
    "# then enter your solution in the interactive problem online to be graded.\n",
    "\n",
    "amps = #LIST OF MAXIMUM AMPLITUDES\n",
    "result_max_amp = #RESULT CORRESPONDING TO MAX AMP\n",
    "\n",
    "result_max_amp.plot()\n",
    "print(\"Time of best fit result: \", ts[np.argmax(amps)])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ts, amps)\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Wave amplitudes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc86192",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    ">#### Follow-up 6.4.3a (ungraded)\n",
    ">    \n",
    ">Try the above exercise, instead sorting by chi-sq values. Does the smallest chi-sq value give you the same t value that you found previously? Why or why not? What other criteria could you use to search for the signal?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c5faf",
   "metadata": {
    "tags": [
     "learner",
     "md"
    ]
   },
   "source": [
    ">#### Follow-up 6.4.3b (ungraded)\n",
    ">    \n",
    ">This took a while to run. But in practice, it's nice to have searches like this run quickly, so that if a wave event is detected, an alert can be sent out to telescopes all over the world and they can look at the correct area of the sky with minimal delay. How could you make this process faster, aside from running it on better hardware?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
